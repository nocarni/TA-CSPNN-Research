{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "import os.path\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "from braindecode.models.deep4 import Deep4Net\n",
    "from braindecode.datasets.bcic_iv_2a import BCICompetition4Set2A\n",
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.experiments.monitors import (\n",
    "    LossMonitor,\n",
    "    MisclassMonitor,\n",
    "    RuntimeMonitor,\n",
    ")\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs, NoDecrease, Or\n",
    "from braindecode.datautil.iterators import BalancedBatchSizeIterator\n",
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "from braindecode.mne_ext.signalproc import mne_apply\n",
    "from braindecode.datautil.signalproc import (\n",
    "    bandpass_cnt,\n",
    "    exponential_running_standardize,\n",
    ")\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "\n",
    "from braindecode.mne_ext.signalproc import resample_cnt\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from TA_CSPNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_config(object):\n",
    "    def __init__(self):\n",
    "        self.channels = 22\n",
    "        self.timesamples = 250\n",
    "        self.timeKernelLen = 64\n",
    "        self.num_classes = 4\n",
    "        self.Ft = 8\n",
    "        self.Fs = 2\n",
    "        self.dropout = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/ncarnigl/TA-CSPNN-Research/bci_2a/A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncarnigl/.local/lib/python3.7/site-packages/mne/io/edf/edf.py:996: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, np.uint8).tolist()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from /home/ncarnigl/TA-CSPNN-Research/bci_2a/A01E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686999  =      0.000 ...  2747.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncarnigl/.local/lib/python3.7/site-packages/mne/io/edf/edf.py:996: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, np.uint8).tolist()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0313 21:38:27.776702 140531481552704 signalproc.py:55] This is not causal, uses future data....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=22, n_times=334918\n",
      "    Range : 0 ... 334917 =      0.000 ...  2690.096 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0313 21:38:31.671991 140531481552704 signalproc.py:55] This is not causal, uses future data....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=22, n_times=342126\n",
      "    Range : 0 ... 342125 =      0.000 ...  2747.992 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0313 21:38:32.427098 140531481552704 deprecation.py:506] From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7048611111111112\n",
      "accuracy: 0.7256944444444444\n",
      "accuracy: 0.6666666666666666\n",
      "accuracy: 0.7222222222222222\n",
      "accuracy: 0.7256944444444444\n",
      "accuracy: 0.71875\n",
      "accuracy: 0.7534722222222222\n",
      "accuracy: 0.7291666666666666\n",
      "accuracy: 0.7569444444444444\n",
      "accuracy: 0.7048611111111112\n",
      "subject_id 1 : accuracy 0.7208333333333334\n",
      "Extracting EDF parameters from /home/ncarnigl/TA-CSPNN-Research/bci_2a/A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncarnigl/.local/lib/python3.7/site-packages/mne/io/edf/edf.py:996: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, np.uint8).tolist()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Extracting EDF parameters from /home/ncarnigl/TA-CSPNN-Research/bci_2a/A02E.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 662665  =      0.000 ...  2650.660 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncarnigl/.local/lib/python3.7/site-packages/mne/io/edf/edf.py:996: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, np.uint8).tolist()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0313 21:45:20.457428 140531481552704 signalproc.py:55] This is not causal, uses future data....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=22, n_times=337230\n",
      "    Range : 0 ... 337229 =      0.000 ...  2708.667 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0313 21:45:23.958452 140531481552704 signalproc.py:55] This is not causal, uses future data....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=22, n_times=330007\n",
      "    Range : 0 ... 330006 =      0.000 ...  2650.651 secs\n",
      "Ready.\n",
      "accuracy: 0.3229166666666667\n",
      "accuracy: 0.34375\n",
      "accuracy: 0.3472222222222222\n",
      "accuracy: 0.2777777777777778\n",
      "accuracy: 0.3611111111111111\n"
     ]
    }
   ],
   "source": [
    "data_folder = './bci_2a'\n",
    "subject_acc = {}\n",
    "models_per_subject = 10\n",
    "subject_data = np.zeros((10,10))\n",
    "for subject_id in range(1,10):\n",
    "    if subject_id == 4:\n",
    "        continue\n",
    "    low_cut_hz = 4\n",
    "    ival = [500, 2500]\n",
    "    max_epochs = 500\n",
    "    max_increase_epochs = 160\n",
    "    batch_size = 60\n",
    "    high_cut_hz = 40\n",
    "    factor_new = 1e-3\n",
    "    init_block_size = 1000\n",
    "    valid_set_fraction = 0.1\n",
    "    sampling_rate = 124.5 # using 125 results in 251 samples\n",
    "\n",
    "    train_filename = \"A{:02d}T.gdf\".format(subject_id)\n",
    "    test_filename = \"A{:02d}E.gdf\".format(subject_id)\n",
    "    train_filepath = os.path.join(data_folder, train_filename)\n",
    "    test_filepath = os.path.join(data_folder, test_filename)\n",
    "    train_label_filepath = train_filepath.replace(\".gdf\", \".mat\")\n",
    "    test_label_filepath = test_filepath.replace(\".gdf\", \".mat\")\n",
    "\n",
    "    train_loader = BCICompetition4Set2A(train_filepath, labels_filename=train_label_filepath)\n",
    "    test_loader = BCICompetition4Set2A(test_filepath, labels_filename=test_label_filepath)\n",
    "    \n",
    "    train_cnt = train_loader.load()\n",
    "    test_cnt = test_loader.load()\n",
    "\n",
    "    train_cnt = train_cnt.drop_channels([\"EOG-left\", \"EOG-central\", \"EOG-right\"])\n",
    "    assert len(train_cnt.ch_names) == 22\n",
    "    # lets convert to millvolt for numerical stability of next operations\n",
    "    train_cnt = mne_apply(lambda a: a * 1e6, train_cnt)\n",
    "    train_cnt = mne_apply(lambda a: bandpass_cnt(a,low_cut_hz,high_cut_hz,\n",
    "                                                 train_cnt.info[\"sfreq\"],filt_order=3,axis=1,),train_cnt,)\n",
    "\n",
    "    train_cnt = mne_apply(lambda a: exponential_running_standardize(a.T,factor_new=factor_new,\n",
    "                          init_block_size=init_block_size,eps=1e-4,).T,train_cnt,)\n",
    "\n",
    "    train_cnt = resample_cnt(train_cnt, sampling_rate)\n",
    "\n",
    "    test_cnt = test_cnt.drop_channels([\"EOG-left\", \"EOG-central\", \"EOG-right\"])\n",
    "    assert len(test_cnt.ch_names) == 22\n",
    "    test_cnt = mne_apply(lambda a: a * 1e6, test_cnt)\n",
    "    test_cnt = mne_apply(lambda a: bandpass_cnt(a,low_cut_hz,high_cut_hz,\n",
    "                                                test_cnt.info[\"sfreq\"],filt_order=3,axis=1,),test_cnt,)\n",
    "    test_cnt = mne_apply(lambda a: exponential_running_standardize(a.T,factor_new=factor_new,\n",
    "                         init_block_size=init_block_size,eps=1e-4,).T,test_cnt,)\n",
    "\n",
    "    test_cnt = resample_cnt(test_cnt, sampling_rate)\n",
    "\n",
    "    marker_def = OrderedDict([\n",
    "            (\"Left Hand\", [1]),\n",
    "            (\"Right Hand\", [2]),\n",
    "            (\"Foot\", [3]),\n",
    "            (\"Tongue\", [4]),\n",
    "        ])\n",
    "\n",
    "    train_set = create_signal_target_from_raw_mne(train_cnt, marker_def, ival)\n",
    "    test_set = create_signal_target_from_raw_mne(test_cnt, marker_def, ival)\n",
    "    train_set, valid_set = split_into_two_sets(\n",
    "        train_set, first_set_fraction=1 - valid_set_fraction\n",
    "    )\n",
    "    x_train = train_set.X[:,None,:,:]\n",
    "    y_train = to_categorical(train_set.y)\n",
    "\n",
    "    x_val = valid_set.X[:,None,:,:]\n",
    "    y_val = to_categorical(valid_set.y)\n",
    "\n",
    "    x_test = test_set.X[:,None,:,:]\n",
    "    y_test = test_set.y\n",
    "\n",
    "    test_acc = 0\n",
    "    best_acc = 0\n",
    "    for i in range(models_per_subject):\n",
    "        config = model_config()\n",
    "        model = TA_CSPNN(config.num_classes, Channels=config.channels, Timesamples=config.timesamples,\n",
    "                        timeKernelLen = config.timeKernelLen, Ft=config.Ft, Fs=config.Fs, dropOut=config.dropout)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics = ['accuracy'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=50)\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=500, validation_data=((x_val, y_val)), \n",
    "                            callbacks=[es],verbose=0)\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "        acc = np.sum(y_pred == y_test) / len(y_test)\n",
    "        test_acc += acc\n",
    "        \n",
    "        print(f\"accuracy: {acc}\")\n",
    "        subject_data[subject_id,i] = acc\n",
    "\n",
    "#         if acc > best_acc:\n",
    "#             print(f\"saving model with acc: {acc}\")\n",
    "#             model.save(f\"models/subject_{subject_id}\")\n",
    "#             best_acc = acc\n",
    "        \n",
    "    test_acc /= models_per_subject\n",
    "    print(f\"subject_id {subject_id} : accuracy {test_acc}\")\n",
    "    subject_acc[subject_id] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in subject_acc.items():\n",
    "    print(f\"{k} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = \"functions/elu\"\n",
    "for i in range(1,10):\n",
    "    if i == 4:\n",
    "        continue\n",
    "    a = subject_data[i]\n",
    "    print(np.mean(a))\n",
    "    np.save(f\"data/{place}/subject_{i}\", a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
